{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TuSimple Lane Detection Challenge - Training Dataset\n",
    "\n",
    "## Description\n",
    "The lane marking is the main component on the highway. It instructs the vehicles interactively and safely drive on the highway. Lane detection is a critical task in autonomous driving, which provides localization information to the control of the car. We provide video clips for this task, and the last frame of each clip contains labelled lanes. The video clip can help algorithms to infer better lane detection results.\n",
    "\n",
    "## Dataset Size\n",
    "3626 video clips, 3626 labelled frames. \n",
    "Information of each clip: 20 frames for each one.\n",
    "\n",
    "## Directory Structure:\n",
    "   \t\t|\n",
    "   \t\t|----readme.md  \t\t\t\t# description\n",
    "   \t\t|\n",
    "   \t\t|----clips/ \t\t\t\t\t# video clips, 3626 clips\n",
    "   \t\t|------|\n",
    "   \t\t|------|----some_clip/\t\t\t# Sequential images for the clip, 20 frames\n",
    "   \t\t|------|----...\n",
    "   \t\t|\n",
    "   \t\t|----label_data_0313.json\t\t\t# Label data for lanes\n",
    "   \t\t|----label_data_0531.json\t\t\t# Label data for lanes\n",
    "   \t\t|----label_data_0601.json\t\t\t# Label data for lanes\n",
    "\n",
    "## Label Data Format\n",
    "Each json line in 'label_data.json' is the label data for __the last (20th) frame__ of this clip.\n",
    "\n",
    "__Format__\n",
    "\n",
    "```\n",
    "    {\n",
    "      'raw_file': str. Clip file path.\n",
    "      'lanes': list. A list of lanes. For each list of one lane, the elements are width values on image.\n",
    "      'h_samples': list. A list of height values corresponding to the 'lanes', which means len(h_samples) == len(lanes[i])\n",
    "    }\n",
    "```\n",
    "Actually there will be at most 5 lane markings in `lanes`. We expect at most 4 lane markings (current lane and left/right lanes). The extra lane is used when changing lane because it is confused to tell which lane is the current lane.\n",
    "\n",
    "The polylines are orgnized by the same distance gap ('h_sample' in each label data) from the recording car. It means you can pair each element in one lane and h_samples to get position of lane marking on images.\n",
    "\n",
    "Also, the lanes are around the center of sight, which we encourage the autonomous driving vehicle to focus on the current lane and left/right lanes. These lanes are essential for the control of the car.\n",
    "\n",
    "For example,\n",
    "```\n",
    "{\n",
    "  \"lanes\": [\n",
    "        [-2, -2, -2, -2, 632, 625, 617, 609, 601, 594, 586, 578, 570, 563, 555, 547, 539, 532, 524, 516, 508, 501, 493, 485, 477, 469, 462, 454, 446, 438, 431, 423, 415, 407, 400, 392, 384, 376, 369, 361, 353, 345, 338, 330, 322, 314, 307, 299],\n",
    "        [-2, -2, -2, -2, 719, 734, 748, 762, 777, 791, 805, 820, 834, 848, 863, 877, 891, 906, 920, 934, 949, 963, 978, 992, 1006, 1021, 1035, 1049, 1064, 1078, 1092, 1107, 1121, 1135, 1150, 1164, 1178, 1193, 1207, 1221, 1236, 1250, 1265, -2, -2, -2, -2, -2],\n",
    "        [-2, -2, -2, -2, -2, 532, 503, 474, 445, 416, 387, 358, 329, 300, 271, 241, 212, 183, 154, 125, 96, 67, 38, 9, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2],\n",
    "        [-2, -2, -2, 781, 822, 862, 903, 944, 984, 1025, 1066, 1107, 1147, 1188, 1229, 1269, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2, -2]\n",
    "       ],\n",
    "  \"h_samples\": [240, 250, 260, 270, 280, 290, 300, 310, 320, 330, 340, 350, 360, 370, 380, 390, 400, 410, 420, 430, 440, 450, 460, 470, 480, 490, 500, 510, 520, 530, 540, 550, 560, 570, 580, 590, 600, 610, 620, 630, 640, 650, 660, 670, 680, 690, 700, 710],\n",
    "  \"raw_file\": \"path_to_clip\"\n",
    "}\n",
    "```\n",
    "`-2` in `lanes` means on some h_sample, there is no existing lane marking. The first existing point in the first lane is `(632, 280)`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load some test images and their ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import json\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# watch for any changes in model.py, if it changes, re-load it automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dataset(json_string, path_prefix = ''):\n",
    "    lanes = json_string['lanes']\n",
    "    num_lanes = len(lanes)\n",
    "    lanes_polyline = [[] for _ in range(num_lanes)]\n",
    "    h_samples = json_string['h_samples']\n",
    "    for h_idx, h in enumerate(h_samples):\n",
    "        for lane_idx in range(num_lanes):\n",
    "            w = lanes[lane_idx][h_idx]\n",
    "            if w >= 0:\n",
    "                lanes_polyline[lane_idx].append((h, w))\n",
    "                \n",
    "    # delete an element if empty\n",
    "    lanes_polyline = [ line for line in lanes_polyline if len(line) != 0]\n",
    "                \n",
    "    image_path = path_prefix + json_string['raw_file']\n",
    "    \n",
    "    return (image_path, lanes_polyline)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training dataset\n",
    "dataset_files = ['tusimple/train_set/label_data_0313.json', \\\n",
    "                 'tusimple/train_set/label_data_0531.json', \\\n",
    "                 'tusimple/train_set/label_data_0601.json']\n",
    "json_lines = []\n",
    "# read all the json strings from the file list\n",
    "for filename in dataset_files:\n",
    "    json_dataset_file = open(filename, 'r')\n",
    "    json_lines.append(json_dataset_file.readlines())\n",
    "# concat all the json lines into one list of newline-terminated strings\n",
    "json_lines = [ line for file_lines in json_lines for line in file_lines ]\n",
    "\n",
    "print('Number of images: {}'.format(len(json_lines)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataset\n",
    "dataset_files = ['tusimple/test_set/test_label.json']\n",
    "\n",
    "json_lines_test = []\n",
    "\n",
    "json_dataset_file = open('tusimple/test_set/test_label.json', 'r')\n",
    "json_lines_test.append(json_dataset_file.readlines())\n",
    "# concat all the json lines into one list of newline-terminated strings\n",
    "json_lines_test = [ line for file_lines in json_lines_test for line in file_lines ]\n",
    "\n",
    "print('Number of images: {}'.format(len(json_lines_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# load a random image from the dataset\n",
    "json_line = random.choice(json_lines)\n",
    "dataset_json = json.loads(json_line)\n",
    "image_path, polylines = parse_dataset(dataset_json, 'tusimple/train_set/')\n",
    "print(image_path)\n",
    "print('num of lane lines: {}'.format(len(polylines)))\n",
    "img = mpimg.imread(image_path)\n",
    "print(np.shape(img))\n",
    "# display the image and detection overlay\n",
    "plt.imshow(img)\n",
    "plt.figure()\n",
    "plt.imshow(img)\n",
    "x = [w for line in polylines for(h,w) in line]\n",
    "y = [h for line in polylines for(h,w) in line]\n",
    "plt.scatter(x,y, c=[(0,1,0)], alpha=0.3)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find out counts of the number of lane lines in an image\n",
    "count_num_lanes = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0}\n",
    "for line in json_lines:\n",
    "    dict_json = json.loads(line)\n",
    "    _, lanelines = parse_dataset(dict_json)\n",
    "    count_num_lanes[len(lanelines)] += 1\n",
    "    \n",
    "count_num_lanes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit a polynomial through the lane lines and find out the vertical bounds\n",
    "# the result would be a vector of length 6 for each lane line\n",
    "# print((len(polylines[2]) == 0))\n",
    "coeffs_and_bounds = np.zeros((7, 5), dtype=np.double)\n",
    "print(np.shape(coeffs_and_bounds))\n",
    "H = np.shape(img)[0]\n",
    "W = np.shape(img)[1]\n",
    "for i, line in enumerate(polylines):\n",
    "    coeffs_and_bounds[0, i] = 1.0\n",
    "    x = [w/W for (h,w) in line] \n",
    "    y = [h/H for (h,w) in line] \n",
    "    coeff = np.polyfit(y,x,3)\n",
    "    c = np.append(coeff, [min(y), max(y)])\n",
    "    print(c)\n",
    "    coeffs_and_bounds[1:,i] = c.T #np.reshape(c, (6,1))\n",
    "\n",
    "np.shape(coeffs_and_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_unity = np.ones((6, 4))\n",
    "# a = np.array([[1,2,3,4,5,6,7]]).T\n",
    "# coeffs_and_bounds[:,:] *= a\n",
    "# coeffs_and_bounds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the dataset\n",
    "The following things are to be done:\n",
    " - Write a ``TUSimpleLaneDataset`` class as an extension of ``torch.Dataset`` and implement its member functions\n",
    " - Define transformation operations (like ``ToTensor()``, ``Rescale()`` etc)\n",
    " - Instantiate torch.Dataloader objects from the ``TUSimpleLaneDataset`` class to supply the data for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from load_data import TUSimpleLaneDataset\n",
    "from load_data import Normalize, Rescale, ReorderLanes, ToTensor, NormalizeImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the transformation steps applied when loading each example\n",
    "data_transforms = transforms.Compose([ \\\n",
    "                                      Rescale((224, 224)), \\\n",
    "                                      ReorderLanes(), \\\n",
    "                                      Normalize(), \\\n",
    "                                      ToTensor(), \\\n",
    "                                      NormalizeImageNet()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a dataset object, which would be the used by the test and train dataloaders.\n",
    "training_dataset = TUSimpleLaneDataset(json_lines, 'tusimple/train_set/', data_transforms)\n",
    "\n",
    "# iterate through the transformed dataset and print some stats about the first few samples\n",
    "for i in range(4):\n",
    "    sample = training_dataset[i]\n",
    "    print(sample['image'].size(), sample['detections'].size())\n",
    "    #print(sample['detections'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a test data loader\n",
    "train_batch_len = 4\n",
    "train_loader = DataLoader(training_dataset, batch_size=train_batch_len, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_detections(image_tensor, detection_tensor):\n",
    "    batch_size = image_tensor.size()[0]\n",
    "    print('batch_size: {}'.format(batch_size))\n",
    "    denormalize = transforms.Normalize(mean=[-0.485/0.229, -0.456/0.224, -0.406/0.225], std=[1/0.229, 1/0.224, 1/0.225])\n",
    "    \n",
    "    for i in range(batch_size):\n",
    "        #print('----------------------------------------')\n",
    "        \n",
    "        image = denormalize(image_tensor[i]).data.numpy()\n",
    "        dtectns = detection_tensor[i].data.numpy().reshape((6,2))\n",
    "        \n",
    "        # plot the image\n",
    "        image = np.transpose(image, (1, 2, 0))\n",
    "        #print('image shape: {}'.format(np.shape(image)))\n",
    "        fig=plt.figure(figsize=(10, 20), dpi= 80, facecolor='w', edgecolor='k')\n",
    "        plt.subplot(2, batch_size, i + 1)\n",
    "        plt.imshow(image)\n",
    "#         plt.figure()\n",
    "        \n",
    "        #plot the detections\n",
    "        max_num_dtectn = 2\n",
    "        colors = ['r', 'g', 'b', 'y', 'w']\n",
    "        for i in range(2):\n",
    "            line_detection = dtectns[:,i]     \n",
    "            coeffs, y_bounds = line_detection[0:4], line_detection[4:6]\n",
    "            image_h, image_w = np.shape(image)[0], np.shape(image)[1]\n",
    "            #print('image shape: {}, {}'.format(image_h, image_w))\n",
    "            y_samples = np.linspace(y_bounds[0], y_bounds[1], 30)\n",
    "            lane_points_x, lane_points_y = [], []\n",
    "            for y in y_samples:\n",
    "                a, b, c, d = coeffs[0], coeffs[1], coeffs[2], coeffs[3]\n",
    "                x = (a * y**3) + (b * y**2) + (c * y) + d\n",
    "                lane_points_x.append(x * image_w)\n",
    "                lane_points_y.append(y * image_h)\n",
    "            #print('coeff: {}, bounds: {}'.format(coeffs, y_bounds))\n",
    "#             plt.imshow(image)\n",
    "            plt.scatter(lane_points_x, lane_points_y, color=colors[i], alpha=0.2, marker='.')\n",
    "            \n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "for i, sample in enumerate(train_loader):\n",
    "    samples.append(sample)\n",
    "    if i == 0:\n",
    "        break\n",
    "for sample in samples:\n",
    "    img = sample['image']\n",
    "    dtections = sample['detections']\n",
    "    print('img shape: {}, dtectn shape: {}'.format(img.size(), dtections.size()))\n",
    "    visualize_detections(img, dtections)\n",
    "    \n",
    "# sample = training_dataset[370]\n",
    "# img = sample['image']\n",
    "# dtections = sample['detections']\n",
    "# print('img shape: {}, dtectn shape: {}'.format(img.size(), dtections.size()))\n",
    "# visualize_detections(img.unsqueeze(0), dtections.unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[9,2,3,4,8]\n",
    "a.sort()\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "\n",
    "import torchvision\n",
    "model = torchvision.models.mobilenet_v2(pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mod in list(model.features.children()):\n",
    "    print('--', mod)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.last_channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "a=torch.randn((2,3,4))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=a.view(a.shape[0], -1)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
    "b=[]\n",
    "b[-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
