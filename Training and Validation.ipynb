{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepPolyLane\n",
    "#### Lane detection expressed as a regression problem rather than a semantic classification.\n",
    "\n",
    "Instead of representing lane lines as lit-up pixels in the output activations of a semantic segmentation CNN, the predictions of this CNN are polynomial coefficients (representing lane lines), their bounds and a set existence probablities. This was loosely inspired from YOLOv1, therefore you could argue that instead of dividing the image space into NxN grids and predicting bounding-box coordinates, this network divides the image space into vertical regions and outputs polynomial coefficients of the lane lines. My hypothesis is that it would remove a bulk of the convolution and de-convolution steps, which are expensive operations for embedded devices.\n",
    "\n",
    "The motivation behind this CNN is to be able to run lane detection on one of my cheap edge AI boards, like Jetson Nano, preferably near real-time. \n",
    "\n",
    "Let's see!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_json_datasets(dataset_files):\n",
    "    json_lines = []\n",
    "    # read all the json strings from the file list\n",
    "    for filename in dataset_files:\n",
    "        json_dataset_file = open(filename, 'r')\n",
    "        json_lines.append(json_dataset_file.readlines())\n",
    "    # concat all the json lines into one list of newline-terminated strings\n",
    "    json_lines = [ line for file_lines in json_lines for line in file_lines ]\n",
    "    return json_lines\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files linked to the training dataset and parse them\n",
    "\n",
    "dataset_files = ['tusimple/train_set/label_data_0313.json', \\\n",
    "                 'tusimple/train_set/label_data_0531.json', \\\n",
    "                 'tusimple/train_set/label_data_0601.json']\n",
    "train_json = read_json_datasets(dataset_files)\n",
    "print('# of training examples: {}'.format(len(train_json)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the files linked to the test/validation dataset and parse them\n",
    "dataset_files = ['tusimple/test_set/test_label.json']\n",
    "val_json = read_json_datasets(dataset_files)\n",
    "print('# of test examples: {}'.format(len(val_json)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomize the new-line terminated strings.\n",
    "import random\n",
    "random.shuffle(train_json)\n",
    "random.shuffle(val_json)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# watch for any changes and re-load it automatically\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup the training and validation data loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "from load_data import TUSimpleLaneDataset\n",
    "from load_data import Normalize, Rescale, ReorderLanes, ToTensor, NormalizeImageNet\n",
    "\n",
    "from utilities import visualize_detections\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# define the transformation steps applied when loading each example\n",
    "data_transforms = transforms.Compose([ \\\n",
    "                                      Rescale((224, 224)), \\\n",
    "                                      ReorderLanes(), \\\n",
    "                                      Normalize(), \\\n",
    "                                      ToTensor(), \\\n",
    "                                      NormalizeImageNet()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a training dataset object, except the last n_valid data points\n",
    "\n",
    "training_dataset = TUSimpleLaneDataset(train_json, 'tusimple/train_set/', data_transforms, cache_enabled=True)\n",
    "\n",
    "# create a test dataset object out the last 100 images in the list.\n",
    "validation_dataset = TUSimpleLaneDataset(val_json, 'tusimple/test_set/', data_transforms, \\\n",
    "                                        cache_enabled=True, cache_size=1200)\n",
    "\n",
    "# iterate through the transformed dataset and print some stats about the first few samples\n",
    "for i in range(4):\n",
    "    sample = training_dataset[i]\n",
    "    print(sample['image'].size(), sample['detections'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a training data loader\n",
    "train_batch_len = 4\n",
    "train_loader = DataLoader(training_dataset, batch_size=train_batch_len, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a validation data loader\n",
    "val_batch_len = 16\n",
    "val_loader = DataLoader(validation_dataset, batch_size=val_batch_len, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "samples = []\n",
    "for i, sample in enumerate(val_loader):\n",
    "    samples.append(sample)\n",
    "    if i == 0:\n",
    "        break\n",
    "for sample in samples:\n",
    "    img = sample['image']\n",
    "    dtections = sample['detections']\n",
    "    print('img shape: {}, dtectn shape: {}'.format(img.size(), dtections.size()))\n",
    "    visualize_detections(img, dtections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import PolyNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import ssl\n",
    "\n",
    "try:\n",
    "    _create_unverified_https_context = ssl._create_unverified_context\n",
    "except AttributeError:\n",
    "    pass\n",
    "else:\n",
    "    ssl._create_default_https_context = _create_unverified_https_context\n",
    "    \n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "# device = \"cpu\"\n",
    "net = PolyNet()\n",
    "net = net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = []\n",
    "for i, sample in enumerate(val_loader):\n",
    "    samples.append(sample)\n",
    "    if i == 0:\n",
    "        break\n",
    "for sample in samples:\n",
    "    img = sample['image']\n",
    "    dtections = sample['detections']\n",
    "    print('img shape: {}, dtectn shape: {}'.format(img.size(), dtections.size()))\n",
    "    pred_geo = net(img.type(torch.FloatTensor).to(device))\n",
    "    pred_geo = pred_geo.view(-1, 6, 2).cpu()\n",
    "    \n",
    "    print('geo_shape: ', pred_geo.shape[0])\n",
    "    #predicted_dtectn = torch.cat([existence, geo], dim=1)\n",
    "    #print('pred shape: ', predicted_dtectn.shape)\n",
    "    visualize_detections(img, dtections)\n",
    "    visualize_detections(img, pred_geo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "The lane_line_loss() takes a pair of tensor of size (batches, 7, 5), of which the first rows are existence scores of\n",
    "of the respective lane-lines and the rest are polynomial coefficients and bounds.\n",
    "'''\n",
    "num_lines = 5\n",
    "def lane_line_loss(predicted, ground_truth):\n",
    "    # reshape tensors into appropriate sizes\n",
    "    \n",
    "    ground_truth = ground_truth.view(-1, 7, num_lines)\n",
    "    expected_existence = ground_truth[:, 0, :].view(-1, num_lines)\n",
    "    expected_geometry = ground_truth[:, 1:, :]\n",
    "    \n",
    "    pred_existence, pred_geometry = predicted\n",
    "    pred_existence = pred_existence.view(-1, num_lines)\n",
    "#     pred_poly = pred_poly.view(-1, 4, num_lines)\n",
    "#     pred_bounds = pred_bounds.view(-1, 2, num_lines)\n",
    "#     pred_geometry = torch.cat([pred_poly, pred_bounds], dim=1)\n",
    "    pred_geometry = pred_geometry.view(-1, 6, num_lines)\n",
    "    \n",
    "    # Compute existence loss\n",
    "    existence_criteria = torch.nn.BCELoss()\n",
    "    existence_loss = existence_criteria(pred_existence, expected_existence)\n",
    "    \n",
    "    n_batch = pred_geometry.shape[0]\n",
    "    \n",
    "    # Compute weighted smooth L1 loss. The weight is either 0 or 1, depending whether the line exists or not\n",
    "    geometry_loss = 0\n",
    "    for i in range(n_batch):\n",
    "        for j in range(num_lines):\n",
    "            weight = expected_existence[i,j]\n",
    "            residual = expected_geometry[i, :, j] - pred_geometry[i, :, j]\n",
    "            norm = torch.norm(residual)\n",
    "            geometry_loss += 0.5 * norm * norm * weight\n",
    "            if norm < 1.0:\n",
    "                geometry_loss += 0.5 * norm * norm * weight\n",
    "            else:\n",
    "                geometry_loss += (norm - 0.5) * weight\n",
    "                \n",
    "    geometry_loss /= n_batch\n",
    "    \n",
    "    return (existence_loss, geometry_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training \n",
    "Time to scorch them GPUs!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.nn import SmoothL1Loss, MSELoss\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "# optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('saved_models/polynet1.pt.bkp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "model_dir = 'saved_models/'\n",
    "model_name = 'polynet1.pt'\n",
    "\n",
    "criteria = SmoothL1Loss()\n",
    "\n",
    "def train_net(n_epochs):\n",
    "    n_train = len(train_loader.dataset)\n",
    "    n_test = len(val_loader.dataset)\n",
    "    best_eval_loss = 10000000000.0\n",
    "    \n",
    "    # Store the losses for plotting.\n",
    "    train_losses = []\n",
    "    eval_losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        net.train()\n",
    "        running_loss = 0.0\n",
    "        train_loss = 0\n",
    "        \n",
    "        for batch_i, data in enumerate(train_loader):\n",
    "            images = data['image']\n",
    "            gt = data['detections']\n",
    "            \n",
    "            gt = gt.view(gt.shape[0], -1) # Flatten the ground truth.\n",
    "            \n",
    "            images = images.type(torch.FloatTensor).to(device)\n",
    "            gt = gt.type(torch.FloatTensor).to(device)\n",
    "            \n",
    "            pred_geo = net(images)\n",
    "            \n",
    "            pred_geo = pred_geo.view(pred_geo.shape[0], -1) # Flatten the prediction\n",
    "            \n",
    "            loss = criteria(pred_geo, gt)\n",
    "        \n",
    "            #existence_loss, geometry_loss = lane_line_loss(predictions, gt)    \n",
    "            #loss = existence_loss + geometry_loss\n",
    "            \n",
    "            \n",
    "            optimizer.zero_grad() # zero the parameter (weight) gradients\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            train_loss += loss.item()\n",
    "            if batch_i % 5 == 0:    # print every 10 batches\n",
    "                print('Epoch: {}, {}/{}, Avg. Loss: {}, (conf, geo) : {}'.format(epoch + 1, (batch_i + 1) * train_batch_len,\\\n",
    "                                                               n_train, running_loss/(10 * train_batch_len),\\\n",
    "                                                               loss.item()), \\\n",
    "                                                               end='\\r')\n",
    "                running_loss = 0.0\n",
    "\n",
    "        train_loss /= n_train\n",
    "        train_losses.append(train_loss)\n",
    "        print('\\nEpoch {}, training loss: {}'.format(epoch + 1, train_loss))\n",
    "        \n",
    "        '''\n",
    "        -------------------\n",
    "        '''\n",
    "        \n",
    "        # evaluate the network performance at the end of every epoch.\n",
    "        print('\\nEvaluating...')\n",
    "        net.eval()\n",
    "        eval_loss = 0\n",
    "        for batch_i, data in enumerate(val_loader):\n",
    "            # get the input image and their labels\n",
    "            \n",
    "            images = data['image']\n",
    "            gt = data['detections']\n",
    "            gt = gt.view(gt.shape[0], -1) # Flatten the ground truth.\n",
    "            \n",
    "            images = images.type(torch.FloatTensor).to(device)\n",
    "            gt = gt.type(torch.FloatTensor).to(device)\n",
    "            \n",
    "            pred_geo = net(images)\n",
    "            \n",
    "            pred_geo = pred_geo.view(pred_geo.shape[0], -1) # Flatten the prediction\n",
    "            \n",
    "            loss = criteria(pred_geo, gt)\n",
    "            \n",
    "            eval_loss += loss.item()\n",
    "            \n",
    "            if batch_i % 5 == 0:    # print every 10 batches\n",
    "                print('Epoch: {}, {}/{}'.format(epoch + 1, (batch_i + 1) * val_batch_len,\\\n",
    "                                                               n_test), \\\n",
    "                                                               end='\\r')\n",
    "        eval_loss = eval_loss / n_test\n",
    "        eval_losses.append(eval_loss)\n",
    "        print('Epoch:{} Avg Eval Loss: {}'.format(epoch + 1, eval_loss))\n",
    "        \n",
    "        # save the best performing model\n",
    "        if(eval_loss < best_eval_loss):\n",
    "            # after training, save your model parameters in the dir 'saved_models'\n",
    "            snapshot_name = model_dir+model_name\n",
    "            print('Saving network: {}'.format(snapshot_name))\n",
    "            torch.save(net.state_dict(), snapshot_name)\n",
    "            best_eval_loss = eval_loss\n",
    "            \n",
    "        # Plot the training and validation losses.\n",
    "        plt.clf()\n",
    "        %matplotlib inline\n",
    "        plt.grid(True)\n",
    "        plt.xlim([0, n_epochs])\n",
    "        plt.plot(train_losses, label = 'training loss')\n",
    "        plt.plot(eval_losses, label = 'validation loss')\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        #plt.show()\n",
    "        plt.savefig('training_curves.png')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_net(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# net.load_state_dict(torch.load('saved_models/polynet1.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utilities import visualize_detections\n",
    "def sample_predictions():\n",
    "    samples = []\n",
    "    for i, sample in enumerate(val_loader):\n",
    "        samples.append(sample)\n",
    "        if i == 0:\n",
    "            break\n",
    "    \n",
    "    img = samples[0]['image']\n",
    "    dtections = samples[0]['detections']\n",
    "    poly = net(img.type(torch.FloatTensor).to(device))\n",
    "    poly = poly.view(-1, 6, 2).cpu()\n",
    "    #bounds = bounds.view(-1, 2, 5).cpu()\n",
    "    #print('detections: {}'.format(poly))\n",
    "    visualize_detections(img[:4], poly[:4])\n",
    "    print('------------------')\n",
    "    #visualize_detections(img[:4], dtections[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sample_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
